---
slug: "build-a-docker-development-environment-for-php-projects/index.html"
title: "Build a PHP development environment your team will love"
intro: "Build a portable development environment for PHP 7.4 with Docker, packed with powerful features to make development easier"
tools: "docker gnu-make php xdebug debian-linux"
date: "03-03-2020"
publish: true
blog: true
category: tutorial
---
import { CodeWave } from "gatsby-theme-waves"
import Code from "components/code"
import ContactLink from "components/contact-link"
import "prismjs/components/prism-docker"
import "prismjs/components/prism-ini"
import "prismjs/components/prism-json"

> Welcome! This post it's a work in progress, that will be changing during the next few days.  
> Don't hesitate to write me an email to <ContactLink/> with any comments, critics or advices you might have.

### Intro

In these days, It's still usual to see many startups, performing manual setup of development environments. 
The results are often a fragile mix of operating systems, libraries, and language versions. 
Other times, development environments are maintained by experienced IT teams, 
who fiercely protect their infrastructure. Affecting the hability of dev teams, to understand the underlying infrastructure, or try new ideas.  
In those scenarios, evolving internal development practices it's impractical and discouraged.

<br/>

In this article, I'll show you how to use Docker, to build a portable development environment for PHP 7.4 applications. With a PHP debugger, profiler, and tracing tools. 
Where developers can experiment agressively, in consistent sandboxed environments, that run fast and locally.

<br/>

Long gone are the days when containerized environments where a practice of a few tech giants, or an unstable technology promoted by crazy early adopters.  
With modern containerization and orchestration tools like Docker, compose, Swarms, or Kubernetes. And modern cloud infrastructure services. 
It is becoming a no brainer for an increasing number of startups, to adopt some of these technologies. In order to provider better experiences for their customers, and cost effective processes for their teams.

### Requirements

To follow this tutorial you need to install **Docker engine** ( mine is 19.03 ), and **GNU Make**.

<br/>

The easiest way to setup Docker in Windows and MacOS is by getting [Docker Desktop](https://www.docker.com/products/docker-desktop).  
GNU Make might be already available in Windows through PowerShell, and its usually present on most popular Linux distros as well as MacOS.  
Linux users can get both via their default package manager. Two popular package managers for other environments are brew (MacOS), and chocolatey (Windows).

<br/>

Next [create a DockerHub account](https://hub.docker.com/signup), and sign in from the command line.

<Code language="bash" snippet={`docker login`} />  

### Basic Docker concepts

With docker you can pack applications with their own environment, build it once, and deploy it to any number of computers running a docker engine.  
Containers share the kernel of their host, and usually run a single process, bundled with the minimum operating system, files, and environment variables required. 
As a result, containers are lighter than virtual machines, and allow detailed resource administration.  
Instead of long lasting dedicated servers, containerized infrastructure can be ephemeral and disposable. Opening the door to new ways of automated, resilient cloud infrastructure, that can adapt to varying demands, and recover from errors.

##### Images

A Docker image it's the blueprint from where containers are created.  
For those comming from object oriented programming, an image can be seen as a class and a container as an instance. 
An image it's just a stopped container.  
Custom images are extended from existing images, and can be shared with others by pushing them to docker repositories.

##### Windows Images vs Linux images

Docker can run two types of images: Linux or Windows images.  
The difference is the kernel they need to interact with in order to access hardware resources. The machine that provides it's kernel, is called host.  
It's possible to run Windows images on a computer running Linux, and visceversa, by running a docker engine on top of a virtual machine.  
Both Windows and MacOS docker versions, run Linux images by default, on top of a lightweight Linux VM. 
However Docker for Windows can spin up Windows images natively.

##### Image layers

You can copy files into an image from your host, add files from a url, create them by running shell commands, or mount a folder from your host as a volume. 
Each of those operations add a new layer to a stack that compounds the resulting image. Each of those layers are like commits in source control software, encapsulating the changes made to the image.  
Every layer is identified with a unique hash ID. And the layer at the top of the stack identifies the image like a GIT branch is identified by it's last commit.  
You can create new containers from any layer on the stack.  
When a new container is created from a given image tag, or layer ID, it is built by summing every change commited on each layer, into a cohesive environment.

##### Inmutable vs mutable images

Usually, managing state on your applications is harder than not doing so. Because state introduces more variables you have to deal with. 
Such is the strength of a functional vs object oriented programming paradigm.  
And something similar happens while building our images; Inmutable images are easier to use than mutable images.

<br/>

Inmutability happens when an image is built with every file needed, and you don't modify their state once deployed.  
Instead of modifying the image while it's running. Once a new version of the code it's available for deployment, you build a new image, deploy it, and remove the old one.  
Overall, inmutable images allows you to implement simpler deployment processes, at the expense of longer build times.

##### Docker networking

Docker relies on the Container Network Model (CNM), a pluggable open-source architecture, to provide networking capabilities.  
CNM is extended to provide different network topologies. 
Docker supports the following implementations out of the box:

- Linux network drivers
    - bridge
    - overlay
    - macvlan
- Windows network drivers
    - nat
    - overlay
    - transparent
    - l2bridge

Many other implementations exist maintained by third parties.  

<br/>

Bridge networks are the default network type when attaching a Linux container port to a host port, as you will see later. Their Windows counter part is NAT.  

<br/>

#### Hello World

This website was built inside a nodejs docker image.    
That means, you can run the same version available at https://guille.cloud, at your local host, without caring or knowing what's under the hoods. 

###### Go ahead and try it

<Code 
language="bash" 
snippet={`docker run --rm 
    -p 8080:8000 
    --name guillecloud 
    guillermomaschwitz/blog:1-production`} 
/>  

An exact version of this website should be available at http://0.0.0.0:8080 or http://localhost:8080.

<br/>

It should work out of the box, cause Docker did all the heavy lifting for you:

1. Attempts to find a local image tagged as **guillermomaschwitz/blog:1-production**
1. If the image is not found locally, docker will attempt to pull it from it's [Dockerhub repository](https://hub.docker.com/r/guillermomaschwitz/blog).
1. A new container with label **guillecloud**, gets started from that image.
1. Localhost's port 8080 gets binded to container's port 8000. 
1. Logs are streamed to the screen through STDOUT and/or STDERR

###### List every image pulled by docker

<Code language="bash" snippet={`docker image ls`} />  

<Code language="terminal" 
snippet={`
REPOSITORY                TAG                 IMAGE ID            CREATED             SIZE
guillermomaschwitz/blog   1                   14699ea162d0        2 hours ago         885MB
guillermomaschwitz/blog   1-production        14699ea162d0        2 hours ago         885MB
node                      13.1.0-alpine       f20a6d8b6721        3 months ago        105MB
`} 
/>

The image with ID **14699ea162d0** belongs to repository **guillermomaschwitz/blog** and have two different tags: **1**, and **1-production**.
It's base image is **f20a6d8b6721**, from repository **node**, with the tag **13.1.0-alpine**.

###### Check if your container is running

<Code language="bash" snippet={`docker container ls`} />  

<Code 
language="terminal"
snippet={`
CONTAINER ID        IMAGE                                  COMMAND                  CREATED             STATUS              PORTS                    NAMES
7ecd413bdf91        guillermomaschwitz/blog:1-production   "docker-entrypoint.s…"   23 minutes ago      Up 23 minutes       0.0.0.0:8000->8000/tcp   guillecloud
`}/>  

If everything went well, you should see a similar list in your terminal; A running container with a unique ID and NAME.

To list stopped containers as well, use the **-a** flag.  

###### Run a command inside the container

You can run bash and play inside your container

<Code language="bash" snippet={`docker exec -it guillecloud bash`} />

<Code language="terminal" 
snippet={`bash-5.0$ whoami
node
bash-5.0$ pwd
/home/node/blog
bash-5.0$ echo "I am inside a container!"
I am inside a container!
bash-5.0$ exit
exit
guille@localhost % `}/>

###### Stop the container

<Code language="bash" snippet={`docker stop guillecloud`} />

Because the container was started with the **--rm** flag, docker destroys the container once stopped.

###### Finally, remove both images from your computer

<Code language="bash" snippet={`docker image rm 14699ea162d0 f20a6d8b6721`} />

<hr/>

## The development environment

### The big picture

The development environment is available for download [at Github](https://github.com/guille-mas/blog/tree/master/code-samples/php-docker-development-environment).  
It contains several files and folders. The most important ones are briefly explained below:

###### php-dev.ini

Settings to make PHP work like it should in a development environment: exposing errors to the user and enabling powerful debugging tools.

###### Dockerfile

This file is the "Rosetta stone" of this tutorial; the recipe used to build a docker environment.

###### Makefile

A high level cli interface other developers can use to interact with the development environment, while they get familiar with docker.  
This is also the place, external tools should rely on to interact with the docker environment. 

###### README.md

Every project that you pass to other devs, should have a clear and concise README file in the root folder. I won't cover this file's content, but you can read it at the root of the project.  
What you write on this file should be the minimal amount of information, needed to introduce others on every basic development workflow.  

###### Other files in the project

- **./src**
    - PHP code that shouldn't be exposed to the public
- **./src/public**
    - Files you want to expose to the public, like a front controller, static assets, etc
- **./data**
    - Folder used by PHP's tracer and profiler to output reports.
- **.gitignore**
    - Flag files to exclude from the GIT repo, like credentials, secrets, vendor files, build constructs, etc.
- **.dockerignore**
    - Flag files to exclude from Docker's context.

<br/>

#### A containerized workflow example

This is an example workflow a development team could adopt to work with this containerized development infrastructure:

A new stable version of the codebase is ready to be deployed to a production server, containing changes to the infrastructure. We call it version 2.0.  
The new codebase contains both: the sourcode of the php app, and the source code of the containerized development environment.

1. The new version is deployed to production and tagged v2.0.
1. A developer in charge of maintaining the development infrastructure's docker image: pulls v1.0 code versions.
    1. Build a new version of the container.
    1. Run automated tests locally.
    1. Push it to the Docker repo with tag v2.0, next to several previous versions of the docker image.
    1. Updates the upstream branch of the source code.
1. Next morning, when a developer pull the latest changes from the upstream stable branch, will get as well an updated version for the docker image to use as a development environment.
1. The dev start the environment, and without knowing it would happen, a new version of the development environment is pulled from the docker repository.
    1. If another developer is working on an older version of the code, it's development environment won't be updated.
1. A third developer realize an improvement could be done to the configuration of the development environment v2.0.
    1. She starts working on the improvement proposal on a new branch.
    1. Updates the hardcoded version of the docker image to use for that version of the sourcecode, to v2.1, after testing it locally.
    1. Open a Merge Request docummenting the improvement.
    1. The maintainer review it, and if approved, the new source code is deployed to production and tagged v2.1.

And the process start again from the beginning.

<br/>

Consider this an example. Each team should adapt their processes to whatever works for them.

<hr/>

### Core files

#### config/php-dev.ini

A development environment should help developers understand their codebase, and catch errors as early as possible. 
The following settings should do the job.

<CodeWave>

```ini
# General
error_reporting = E_ALL
display_startup_errors = On
display_errors = On
````

##### Errors

Developers should have complete visibility over any error or exception that might rise at run time. 

- **error_reporting = E_ALL** enable output of every message sent to php error logs
- **display_startup_errors = On** enable PHP's startup errors reporting
- **display_errors = On** print errors to the screen as part of the output

```ini
# Debugger
xdebug.remote_enable=1
xdebug.remote_autostart=0
xdebug.remote_host="host.docker.internal"
xdebug.remote_mode=req
xdebug.remote_port=9001
````

##### PHP Debugger

Using a PHP debugger will make a **huge difference in your productivity** as a PHP developer.  
If you are debugging issues with var_dump() or print_r() you should really try this approach instead.

<br/>

The thing with this debugger, is that it's not suitable for shared development servers, or servers exposed to the wild. 
But it is very easy to make it work from a locally running docker container.

<br/>

With these settings, an HTTP request, containing the parameter **XDEBUG_SESSION_START** will start a debugging session.  
You can use [Chrome's XDebug Helper](https://chrome.google.com/webstore/detail/xdebug-helper/eadndfjplgieldjbigjakmdgkmoaaaoc) to help you attach that param to any request.

<br/>

###### This is how a PHP debugging session works:

1. Your must tell your editor to listen on port 9001 for incoming connections. If the editor doesn't support that out of the box, look for a plugin.
1. An HTTP request containing the param **XDEBUG_SESSION_START** is sent to the web server
1. XDebug pause the flow of your program, attempts to connect back to your computer at localhost:9001, and waits for your orders.
1. Your editor accepts the connection
1. If there is a breakpoint in your code, the web server will halt it's execution there, and send to your editor, all the information available about the current context.

From there, you will have complete visibility on every variable, constant, object, created on the current context, and every frame of the memory stack of your PHP programs.  
You can use the debugger like you would use a javascript debugger from your browser.

<br/>

You can use [Chrome's XDebug Helper](https://chrome.google.com/webstore/detail/xdebug-helper/eadndfjplgieldjbigjakmdgkmoaaaoc) to help you attach that param to any request.

> Using the PHP debugger **will increase your productivity** as a PHP developer !!

<br/>

A few useful resources to setup an IDE or editor to debug requests:

- [Felix Becker PHP Xdebug plugin for VSCode](https://marketplace.visualstudio.com/items?itemName=felixfbecker.php-debug)
- [Howto setup PHP Xdebug in PHPStorm](https://www.jetbrains.com/help/phpstorm/creating-php-web-application-debug-configuration.html)
- [PHP Xdebug plugin for Sublime 2 and 3](https://packagecontrol.io/packages/Xdebug%20Client)

This is my VSCode configuration for FelixBecker's plugin, in case you are using VSCode:

<Code
language="json"
snippet={`
{
  "version": "0.2.0",
  "configurations": [
    {
      "name": "My project",
      "type": "php",
      "request": "launch",
      "port": 9001,
      "pathMappings": {
        "/var/www": "\$\{workspaceFolder\}/src"
      }
    }
  ]
}
`} />





```ini
# Profiler
xdebug.cli_color=1
xdebug.profiler_enable=0
xdebug.profiler_enable_trigger=1
xdebug.profiler_output_dir="/tmp/mydata"
xdebug.profiler_output_name="cachegrind.out.%H.%t.%p"
````

##### PHP Profiler

Enabled by an HTTP parameter **XDEBUG_PROFILE**. 
XDebug's PHP profiler will produce a complete report of the messages passed between functions and/or objects in your PHP programs during a specific request.
Then you can open those reports with [KCacheGrind](https://kcachegrind.github.io/), [QCacheGrind](http://sourceforge.net/projects/qcachegrindwin/), [WinCacheGrind](http://ceefour.github.io/wincachegrind/), or [WebGrind](https://github.com/jokkedk/webgrind) .  
This is useful when you want to understand what happens on a new project, or how a framework works under the hoods.


```ini
# Tracer
xdebug.trace_enable_trigger=1
xdebug.show_mem_delta=1
xdebug.trace_output_dir="/tmp/mydata"
xdebug.trace_output_name="trace.%H.%t.%p"
xdebug.collect_params=3
```

##### PHP Tracer

XDebug tracer is a powerful tool that gives you the ability to analyze your PHP code, detect bottlenecks, and understand memory consumption at every step in a given flow.

<br/>

Reports are human readable and are stored in container's folder /tmp/mydata.  
Later I show you howto map that folder with a local folder in your host, to read those reports more easily.

<br/>

To enable the tracer, add the HTTP parameter **XDEBUG_TRACE** to any HTTP request. 
Again, you can use [Chrome's XDebug Helper](https://chrome.google.com/webstore/detail/xdebug-helper/eadndfjplgieldjbigjakmdgkmoaaaoc) to help you attach that param to any request.

</CodeWave>

<br/>

<br/>

#### The Dockerfile

Docker uses Dockerfiles as recipes to create images. Let's explore it's syntax and a few useful instructions.

<CodeWave>

```docker
# My PHP Development environment
FROM php:7.4.2-apache
```

##### Use an official base image

**FROM** tells docker which base image has to use for subsequent instructions. 
Because of this, it's the first instruction on the Dockerfile.   
Every image is tagged with the following syntax:

<br/>

< **name** > **:** [ **version** ]

<br/>


Docker has a vibrant ecosystem of images you can use. One of the most popular repositories places to look for it's [DockerHub](https://hub.docker.com/), with thousands of publicly available repositories, built by devops practitioners around the world.  

<br/>

The image you choose must exist and you need to have access to it.  
Use the [official PHP image, bundled with Apache](https://hub.docker.com/_/php), whose name its "php", and its version "7.4.2-apache". 
If you want to check it's source code, [read its Dockerfile from Github](https://github.com/docker-library/php/blob/master/7.4/buster/apache/Dockerfile).  
To protect your image from upstream's breaking changes, always use explicit version tags. This principle applies to every external dependency you use in your projects, from Docker images to composer and npm packages.

<br/>

> For improved security and stability, your custom images should rely on [official images](https://docs.docker.com/docker-hub/official_images/); A curated list of images maintained by stricter quality standards

<br/>

```docker
# My PHP Development environment
FROM php:7.4.2-apache AS dev-image
```

##### Choose an alias for your image

An alias help you reference one of your images in your build process. In this case the alias is **dev-image**.  

<br/>

Many image definitions can be written on the same Dockerfile.  
An alias help you identify a specific image.

```docker
# My PHP Development environment
FROM php:7.4.2-apache AS dev-image
# Install XDebug
RUN pecl install xdebug-2.8.1
RUN docker-php-ext-enable xdebug
```

##### Run shell commands

First, install [XDebug](https://xdebug.org/); A development PHP extension that packs handy features to make your life easier as a developer.  
As [docummented here](https://hub.docker.com/_/php), use _pecl_, and _docker-php-ext-enable_ instead of apt-get or other methods.  

<br/>

You can use RUN as many times as you want, but keep in mind it will generate a new layer, increasing the resulting image's size.

<br/>

```docker
# My PHP Development environment
FROM php:7.4.2-apache AS dev-image
# Install XDebug
RUN pecl install xdebug-2.9.2 \
    && docker-php-ext-enable xdebug
```

##### Optimize the size of your image

You can chain shell commands together in order to reduce the amount of layers that compound an image.

> Unless you want to cache specific steps of your build process, it's a good practice to replace consecutive RUN lines, by a single line of chained sentences


```docker
# My PHP Development environment
FROM php:7.4.2-apache AS dev-image
# Install XDebug
RUN pecl install xdebug-2.9.2 \
    && docker-php-ext-enable xdebug \
# Create data folders for XDebug
# tracing and profiling tools
# and set ownership to www-data
    && mkdir -p /tmp/mydata \
    && chown -R www-data:www-data /tmp/mydata
# copy development settings for PHP
COPY ./config/development.ini /usr/local/etc/php/conf.d/
```

##### Configure PHP and XDebug

**COPY** allows you to copy files and folders from your host into your image.

1. Let's **RUN** a command to create a folder  /tmp/mydata inside your image; The place to store output files generated with XDebug tracer and profiler (see config/development.ini).
1. **COPY** the file config/development.ini into /usr/local/etc/php/conf.d/ inside your image, so PHP can load your settings automatically


```docker
# My PHP Development environment
FROM php:7.4.2-apache AS dev-image
# Install XDebug
RUN pecl install xdebug-2.9.2 \
    && docker-php-ext-enable xdebug \
# Create data folders for XDebug
# tracing and profiling tools
# and set ownership to www-data
    && mkdir -p /tmp/mydata \
    && chown -R www-data:www-data /tmp/mydata
# copy development settings for PHP
COPY ./config/development.ini /usr/local/etc/php/conf.d/
# copy the PHP source code inside your image
COPY --chown=www-data:www-data ./src /usr/local/project
# symling your project folder 
# with default's public apache folder
RUN ln -s /usr/local/project/public /var/www/html
```

##### Copy your project source code inside the image

1. **COPY** your local folder src/ into /usr/local/project inside your images, and assign the ownership of those files to user www-data
2. Then use **RUN** to symlink /var/www/html to /usr/local/project/public folder

**--chown=user:group** sets ownership of those files.

```docker
# My PHP Development environment
FROM php:7.4.2-apache AS dev-image
# Install XDebug
RUN pecl install xdebug-2.9.2 \
    && docker-php-ext-enable xdebug \
# Create data folders for XDebug
# tracing and profiling tools
# and set ownership to www-data
    && mkdir -p /tmp/mydata \
    && chown -R www-data:www-data /tmp/mydata
# copy development settings for PHP
COPY ./config/development.ini /usr/local/etc/php/conf.d/
# copy the PHP source code inside your image
COPY --chown=www-data:www-data ./src /usr/local/project
# symling your project folder 
# with default's public apache folder
RUN ln -s /usr/local/project/public /var/www/html
EXPOSE 80
```

##### Expose ports

**EXPOSE** open one or multiple ports in the container.

<br/>

This is just an example, cause there's no need to expose port 80, since it's been done already on the base image.  

<br/>

```docker
# My PHP Development environment
FROM php:7.4.2-apache AS dev-image
# Install XDebug
RUN pecl install xdebug-2.9.2 \
    && docker-php-ext-enable xdebug \
# Create data folders for XDebug
# tracing and profiling tools
# and set ownership to www-data
    && mkdir -p /tmp/mydata \
    && chown -R www-data:www-data /tmp/mydata
# copy development settings for PHP
COPY ./config/development.ini /usr/local/etc/php/conf.d/
# copy the PHP source code inside your image
COPY --chown=www-data:www-data ./src /usr/local/project
# symling your project folder 
# with default's public apache folder
RUN ln -s /usr/local/project/public /var/www/html
EXPOSE 80
```

##### And that's it!

You can now use this Dockerfile to build your custom image.

<br/>

Check [the Dockerfile reference](https://docs.docker.com/engine/reference/builder/) for a deep dive into every option available to write your own images, or customize this example.

</CodeWave>

<br/>

<br/>

### Basic docker workflows

#### Previous Steps

Before building the environment, allow Docker to read your project's folder.  
At least in Docker Desktop for MacOS, it goes like this:  

1. Go to Docker Desktop's preferences
2. Go to File Sharing, under Resources section
3. Add your folder and apply changes

Avoid symlinked folders cause Docker doesn't like them.

#### Let's do it

###### Build your image

<Code language="bash" snippet={`docker build -t my-project:1.0-development --target dev-image .`} />

Builds and tags your image as **my-project:1.0-development**.  
The last parameter ".", is the file system context at your docker host. Any file you want to **COPY** into the image, must be inside the given context. 
You should allow docker to access your project's folder first. See the "File Sharing" settings section in Docker for Desktop.

<br/>

If everything went well, you should see **my-project** custom image between your locally available images.

<Code language="bash" snippet={`docker image ls`} />

<Code 
language="bash" 
snippet={`
REPOSITORY                  TAG                 IMAGE ID            CREATED             SIZE
dockerhub-user/my-project   1.0-development     14699ea162d0        2 minutes ago       885MB
`} />

###### Test it as a standalone container

Test your image before sharing it.  
Do not mount any volume, because you want to test the image itself as an inmutable artifact.

<Code 
language="bash" 
snippet={`docker run --rm 
    -p 80:80/tcp 
    --name my-project-container 
    my-project:1.0-development`} 
/>

###### Run it as a development environment

How can you use this image as a development environment?  
Simply by mounting your source code inside the environment.

<br/>

Let's run a new container, with your source code mounted into it. 
And mount as well a local "data/" folder, as the folder where XDebug profiler and tracer dump their files inside the container. 
That way you can read them from your host.  
Use the **-v host-folder:container-folder** parameters for each volume.  
You should also use **--rm** to tell Docker to discard the container after using it.

<Code 
language="bash" 
snippet={`docker run --rm 
    -p 80:80/tcp
    -v "$PWD"/src:/usr/local/project 
    -v "$PWD"/data:/tmp/mydata 
    --name my-project-container 
    my-project:1.0-development`} 
/>

###### Share your image

To share it with other developers, push the image to your Dockerhub repo.

<Code 
language="bash" 
snippet={`docker login`}
/>

<Code 
language="bash" 
snippet={`docker push your-dockerhub-username/my-project`}
/>

<br/>

<br/>

#### Wrapping each workflow into a cohesive interface

Just like you would define an interface, or a group of public methods in a PHP class, so others can reuse it, without studying your implementation.  
You should expose a simple list of commands, so others can use your environment, without knowing about docker.  
Of course, it's code should be clear and well docummented, to allow anyone curious, to learn more about it.
Let's see now howto define a high level cli inteface, by writing a Makefile compatible with GNUMake.  
The list of commands shuld be as similar as possible across projects, to reduce complexity and favor reuse.  
GNUMake it's a good fit for this task, because it allows you to write every high level command in a single file, and it's a tool available on most operating systems.

<br/>

These are a few commands I like to define for projects in general:

- make build
- make clean
- make all
- make start
- make stop
- make test


<CodeWave>

```makefile
build:
	docker build \
    -t my-project:1.0-development \
    --target dev-image .
````

##### make build

Build the development environment.  
In the case of multiple environments, it should build every image required by any environment.  

<br/>

This command is used by the maintainers of the environment, and a CI/CD pipeline.


```makefile
start:
	docker run --rm \
    -p 80:80/tcp \
    -v ${PWD}/src:/var/www/html \
    -v ${PWD}/data:/tmp/mydata \
    --name my-project-container \
    acme/my-project:1.0-development
````

##### make start

Use this command to start a local development environment. It's usually used by developers involved in the project.  

- Docker will pull my-project:1.0-development image from acme´s docker repository
- Map ports with the developer computer
- Assigns a name to the container (useful to write other commands like "make stop")
- Mount the source code inside the container so the environment can reflect changes made to the code.

```makefile
exec:
	@read -p "Command: " command; \
	docker exec \
    my-project-container \
    sh -c "$$command"
````

##### make exec

The all idea of containerizing a development environment, is to run a project in a predictable environment.  
Which should resemble as close as possible a production environment.  

<br/>

**make exec** it's a helper command that execute any command you pass to it inside the container, previously started with **make start**

<br/>

###### Example commands you should run with **make exec**:

<Code language="bash" snippet={`composer install`} />

<Code language="bash" snippet={`composer update`} />

<Code language="bash" snippet={`npm install`} />

<Code language="bash" snippet={`ifconfig`} />

<Code language="bash" snippet={`apt install nmap curl`} />


```makefile
stop: 
	-docker container stop my-project-container
````

##### make stop

This command stops the container previously started with **make start*

```makefile
clean: stop	
	-docker container rm my-project-container
	docker image rm my-project:1.0-development
````

##### make clean

This command removes any artifact created during the build by **make build**.  

<br/>

It's usually used by the maintainers of the environment and a CI/CD pipeline.

</CodeWave>

It's important to implement a common set of commands across projects to ease understanding and integration with automation tools. 
I like to use commands like: build, clean, start, stop, deploy, test, all. 
Because are concise and self descriptive, besides being some of them pretty common across other projects I've seen in the wild.

<br/>

#### The README.md

Always remember to wrap your environment with a high level docummentation, so those who have to work with it, can move faster without depending on you.  
Docummentation is critical for communication, and reduce the dependency a team has on the maintainer of the environment.
It also helps to spread the knowledge about the product, which is something very good if you plan to go on vacations someday.

<br/>

<hr/>

### Final thoughts

I hope you found this tutorial useful!  
Hopefully, you learned enough about Docker to build your own development environments.  
There is still more to learn though. This is a single container environment and it's not suitable for production. 
But it's the corner stone to modernize processes and stimulate better, more enjoyable, collaborative ways of building software together.

<br/>

I did my best to guide you through this introductory exploration of Docker concepts, and a few use cases.
Above all, I tried to share a few technical tricks to improve collaboration and communication.

<br/>

Feel free to let me know any comments, critics, or suggestions you might have.  
You can write me at <ContactLink/>

### Whats next

In my next post I'll show you how to build a production version of this environment, with **docker multi-stage builds**. 
How to create sandboxed **docker networks** to connect multiple containers together. 
And **docker-compose**, an interesting tool to declare your dev infrastructure in yaml format.

<br/>

**Stay tuned!**


