---
slug: "build-a-docker-development-environment-for-php-projects/index.html"
title: "Build a PHP development environment your team will love"
intro: "Build a portable development environment for PHP 7.4 with Docker, packed with powerful features to make development easier"
tools: "docker gnu-make php xdebug debian-linux"
date: "March 4th, 2020"
publish: true
blog: true
category: tutorial
---
import { CodeWave } from "gatsby-theme-waves"
import Code from "components/code"
import ContactLink from "components/contact-link"
import "prismjs/components/prism-docker"
import "prismjs/components/prism-ini"
import "prismjs/components/prism-json"

> Welcome! This post it's a work in progress, that will be changing during the next few days.  
> Don't hesitate to write me an email to <ContactLink/> with any comments, critics or advices you might have.

### Intro

In these days, it's quite usual to see startups, performing manual setup of development environments. 
The results are often a fragile mix of operating systems, libraries, and language versions. 
On other occasions,  experienced IT teams are responsible for building these environments, protecting them from inexperienced developers.  
As a side effect, development teams experience blockers, to understand the underlying infrastructure, or try new ideas.
In those scenarios, evolving internal development practices it's impractical and discouraged.

<br/>

In this article, I'll show you how to use Docker, to build a portable development environment for PHP 7.4 applications. With a PHP debugger, profiler, and tracing tools. 
Where developers can experiment aggressively, on fast sandboxed environments.

<br/>

Long gone are the days when containerized environments where a practice of a few tech giants, or an unstable technology promoted by crazy early adopters.  
With modern containerization and orchestration tools like Docker, docker-compose, Swarms, or Kubernetes. And modern cloud infrastructure services. 
It is becoming a no brainer for an increasing number of startups, to adopt some of these technologies. 
To provide better experiences for their customers, and cost-effective processes for their teams.

### Requirements

To follow this tutorial you need to install the **Docker engine**, and **GNU Make**.

<br/>

The easiest way to setup Docker in Windows and MacOS is by getting [Docker Desktop](https://www.docker.com/products/docker-desktop).  
GNU Make might be already available in Windows through PowerShell, and it's usually present on most popular Linux distros as well as MacOS.  
Linux users can get both via their default package manager. Two popular package managers for other environments are brew (MacOS), and chocolatey (Windows).

<br/>

Next, create a [DockerHub account](https://hub.docker.com/signup), and sign in from the command-line.

<Code language="bash" snippet={`docker login`} />  

### Basic Docker concepts

With docker, you can pack applications with their environment, build it once, and deploy it to any number of computers running a docker engine.  
Containers share the kernel of their host, and usually run a single process, bundled with the minimum operating system, files, and environment variables required. 
As a result, containers are lighter than virtual machines and allow detailed resource administration.  
Instead of long-lasting dedicated servers, containerized infrastructure can be ephemeral and disposable. Opening the door to new ways of automated, resilient cloud infrastructure, that can adapt to varying demands, and recover from errors.

##### Images

A Docker image it's the blueprint from where containers are created.  
For those coming from object-oriented programming, an image can be seen as a class and a container as an instance. 
An image it's just a stopped container.  
Custom images are extended from existing images and can be shared with others by pushing them to docker repositories.

##### Windows Images vs Linux images

Docker can run two types of images: Linux or Windows images.  
The difference is the kernel they need to interact with to access hardware resources. The machine that provides its kernel, is called host.  
It's possible to run Windows images on a computer running Linux, and visce versa, by running a docker engine on top of a virtual machine.  
Both Windows and MacOS docker versions, run Linux images by default, on top of a lightweight Linux VM. 
However, Docker for Windows can spin up Windows images natively.

##### Image layers

You can copy files into an image from your host, add files from a URL, create them by running shell commands, or mount a folder from your host as a volume. 
Each of those operations adds a new layer to a stack that compounds the resulting image. Each layer it's like a GIT commit, encapsulating the changes made to the image.  
Every layer is identified with a unique hash ID. And the layer at the top of the stack identifies the image like a GIT branch is identified by its last commit.  
You can create new containers from any layer on the stack.  
When a new container is created from a given image tag or layer ID, it is built by summing every layer together, into a cohesive environment.

##### Immutable vs mutable images

Usually, managing state on your applications is harder than not doing so. Because state introduces more variables you have to deal with. 
Such is the strength of a functional vs object oriented programming paradigm.  
And something similar happens with infrastructure-as-code; Deployment of immutable images are easier to implement.

<br/>

Immutability happens when an image is built with every file needed, and you don't modify their state once deployed.  
Instead of modifying the image while it's running. Once a new version of the code it's available for deployment, you build a new image, deploy it, and remove the old one.  
Overall, immutable images allows you to implement simpler deployment processes, at the expense of longer build times.

##### Docker networking

Docker relies on the Container Network Model (CNM), a pluggable open-source architecture, to provide networking capabilities.  
CNM is extended to provide different network topologies. 
Docker supports the following implementations out of the box:

- Linux network drivers
    - bridge
    - overlay
    - macvlan
- Windows network drivers
    - nat
    - overlay
    - transparent
    - l2bridge

Many other implementations exist maintained by third parties.  

<br/>

Bridge networks are the default network type when attaching a Linux container port to a host port, as you will see later. Their Windows counterpart is NAT.  

<br/>

#### Hello World

This website was built inside a nodejs docker image.    
That means you can run the same version available at https://guille.cloud, at your localhost, without caring or knowing what's under the hoods. 

###### Go ahead and try it

<Code 
language="bash" 
snippet={`docker run --rm 
    -p 8080:8000 
    --name guillecloud 
    guillermomaschwitz/blog:1-production`} 
/>  

An exact version of this website should be available at http://0.0.0.0:8080 or http://localhost:8080.

<br/>

It should work out of the box, cause Docker did all the heavy lifting for you:

1. Attempts to find a local image tagged as **guillermomaschwitz/blog:1-production**
1. If the image is not found locally, docker will attempt to pull it from its [Dockerhub repository](https://hub.docker.com/r/guillermomaschwitz/blog).
1. A new container with label **guillecloud**, gets started from that image.
1. Binds localhost's port 8080 to container's port 8000.
1. Logs are streamed to the screen through STDOUT and/or STDERR

###### List every image pulled by docker

<Code language="bash" snippet={`docker image ls`} />  

<Code language="terminal" 
snippet={`
REPOSITORY                TAG                 IMAGE ID            CREATED             SIZE
guillermomaschwitz/blog   1                   14699ea162d0        2 hours ago         885MB
guillermomaschwitz/blog   1-production        14699ea162d0        2 hours ago         885MB
node                      13.1.0-alpine       f20a6d8b6721        3 months ago        105MB
`} 
/>

The image with ID **14699ea162d0** belongs to the repository "**guillermomaschwitz/blog**" and have two different tags: "**1**", and "**1-production**".
Its base image is **f20a6d8b6721**, from the "**node**"" repository , with the tag "**13.1.0-alpine**".

###### Check if your container is running

<Code language="bash" snippet={`docker container ls`} />  

<Code 
language="terminal"
snippet={`
CONTAINER ID        IMAGE                                  COMMAND                  CREATED             STATUS              PORTS                    NAMES
7ecd413bdf91        guillermomaschwitz/blog:1-production   "docker-entrypoint.s…"   23 minutes ago      Up 23 minutes       0.0.0.0:8000->8000/tcp   guillecloud
`}/>  

If everything went well, you should see a similar list in your terminal; A running container with a unique ID and NAME.

To list stopped containers as well, use the **-a** flag.  

###### Run a command inside the container

You can run bash and play inside your container

<Code language="bash" snippet={`docker exec -it guillecloud bash`} />

<Code language="terminal" 
snippet={`bash-5.0$ whoami
node
bash-5.0$ pwd
/home/node/blog
bash-5.0$ echo "I am inside a container!"
I am inside a container!
bash-5.0$ exit
exit
guille@localhost % `}/>

###### Stop the container

<Code language="bash" snippet={`docker stop guillecloud`} />

Because the container was started with the **--rm** flag, docker destroys the container once stopped.

###### Finally, remove both images from your computer

<Code language="bash" snippet={`docker image rm 14699ea162d0 f20a6d8b6721`} />

<hr/>

## The development environment

### The big picture

The development environment is available for download [at Github](https://github.com/guille-mas/blog/tree/master/code-samples/php-docker-development-environment).  
It contains several files and folders. The most important ones are briefly explained below:

###### php-dev.ini

Settings to make PHP work like it should in a development environment: exposing errors to the user and enabling powerful debugging tools.

###### Dockerfile

This file is the "Rosetta stone" of this tutorial; the recipe used to build a docker environment.

###### Makefile

A high-level command-line interface other developers can use to interact with the development environment, while they get familiar with docker.  
This is also the place, external tools should rely on to interact with the docker environment. 

###### README.md

Every project that you pass to other devs, should have a clear and concise README file in the root folder. I won't cover this file's content, but you can read it at the root of the project.  
What you write on this file should be the minimal amount of information, needed to introduce others on every basic development workflow.  

###### Other files in the project

- **./src**
    - PHP code that shouldn't be exposed to the public
- **./src/public**
    - Files you want to expose to the public, like a front controller, static assets, etc
- **./data**
    - Folder used by PHP's tracer and profiler to output reports.
- **.gitignore**
    - Flag files to exclude from the GIT repo, like credentials, secrets, vendor files, build constructs, etc.
- **.dockerignore**
    - Flag files to exclude from Docker's context.

<br/>

#### A containerized workflow example

This is an example workflow a development team could adopt to work with this containerized development infrastructure:

A new stable version of the codebase is ready to be deployed to a production server, containing changes to the infrastructure. We call it version 2.0.  
The new codebase contains both: the sourcecode of the PHP app, and the source code of the containerized development environment.

1. The new version is deployed to production and tagged v2.0.
1. A developer in charge of maintaining the development infrastructure's docker image: pulls v1.0 code versions.
    1. Build a new version of the container.
    1. Run automated tests locally.
    1. Push it to the Docker repo with tag v2.0, next to several previous versions of the docker image.
    1. Updates the upstream branch of the source code.
1. The next morning, when a developer pull the latest changes from the upstream stable branch, will get as well an updated version for the docker image to use as a development environment.
1. The dev start the environment, and without knowing it would happen, a new version of the development environment is pulled from the docker repository.
    1. If another developer is working on an older version of the code, it's development environment won't be updated.
1. A third developer realize an improvement could be done to the configuration of the development environment v2.0.
    1. She pushes the improvement to a new branch.
    1. Open a Merge Request and assign it to the maintainer.
    1. The maintainer review it, and if approved, the new source code is deployed to production and tagged v2.1.

<hr/>

### Core files

#### config/php-dev.ini

A development environment should help developers to understand their codebase, and catch errors as early as possible. 
The following settings should do the job.

<CodeWave>

```ini
# General
error_reporting = E_ALL
display_startup_errors = On
display_errors = On
````

##### Errors

Developers should have complete visibility over any error or exception that might rise at run time. 

- **error_reporting = E_ALL** enable output of every message sent to PHP error logs
- **display_startup_errors = On** enable PHP's startup errors reporting
- **display_errors = On** print errors to the screen as part of the output

```ini
# Debugger
xdebug.remote_enable=1
xdebug.remote_autostart=0
xdebug.remote_host="host.docker.internal"
xdebug.remote_mode=req
xdebug.remote_port=9001
````

##### PHP Debugger

Using a PHP debugger will make a **huge difference in your productivity** as a PHP developer.  
If you are debugging issues with var_dump() or print_r() you should really try this approach instead.

<br/>

This debugger isn't suitable for shared development servers, or servers exposed to the wild. 
But it's very easy to make it work from a locally running docker container.

<br/>

With these settings, an HTTP request, containing the parameter **XDEBUG_SESSION_START** will start a debugging session.  
You can use [Chrome's XDebug Helper](https://chrome.google.com/webstore/detail/xdebug-helper/eadndfjplgieldjbigjakmdgkmoaaaoc) to help you attach that param to any request.

<br/>

###### This is how a PHP debugging session works:

1. You must tell your editor to listen on port 9001 for incoming connections. If the editor doesn't support that out of the box, look for a plugin.
1. An HTTP request containing the param **XDEBUG_SESSION_START** is sent to the webserver
1. XDebug pauses the flow of your program, attempts to connect back to your computer at localhost:9001, and waits for your orders.
1. Your editor accepts the connection
1. If there is a breakpoint in your code, the webserver will halt it's execution there, and send it to your editor, all the information available about the current context.

From there, you will have complete visibility on every variable, constant, object, created on the current context, and every frame of the memory stack of your PHP programs.  
You can use the debugger like you would use a javascript debugger from your browser.

<br/>

You can use [Chrome's XDebug Helper](https://chrome.google.com/webstore/detail/xdebug-helper/eadndfjplgieldjbigjakmdgkmoaaaoc) to help you attach that param to any request.

> Using the PHP debugger **will increase your productivity** as a PHP developer !!

<br/>

A few useful resources to set up an IDE or editor to debug requests:

- [Felix Becker PHP Xdebug plugin for VSCode](https://marketplace.visualstudio.com/items?itemName=felixfbecker.php-debug)
- [How to setup PHP Xdebug in PHPStorm](https://www.jetbrains.com/help/phpstorm/creating-php-web-application-debug-configuration.html)
- [PHP Xdebug plugin for Sublime 2 and 3](https://packagecontrol.io/packages/Xdebug%20Client)

This is my VSCode configuration for FelixBecker's plugin, in case you are using VSCode:

<Code
language="json"
snippet={`
{
  "version": "0.2.0",
  "configurations": [
    {
      "name": "My project",
      "type": "php",
      "request": "launch",
      "port": 9001,
      "pathMappings": {
        "/var/www": "\$\{workspaceFolder\}/src"
      }
    }
  ]
}
`} />





```ini
# Profiler
xdebug.cli_color=1
xdebug.profiler_enable=0
xdebug.profiler_enable_trigger=1
xdebug.profiler_output_dir="/tmp/mydata"
xdebug.profiler_output_name="cachegrind.out.%H.%t.%p"
````

##### PHP Profiler

Enabled by an HTTP parameter **XDEBUG_PROFILE**. 
XDebug's PHP profiler will produce a complete report of the messages passed between functions and/or objects in your PHP programs during a specific request.
Then you can open those reports with [KCacheGrind](https://kcachegrind.github.io/), [QCacheGrind](http://sourceforge.net/projects/qcachegrindwin/), [WinCacheGrind](http://ceefour.github.io/wincachegrind/), or [WebGrind](https://github.com/jokkedk/webgrind) .  
This is useful when you want to understand what happens on a new project, or how a framework works under the hoods.


```ini
# Tracer
xdebug.trace_enable_trigger=1
xdebug.show_mem_delta=1
xdebug.trace_output_dir="/tmp/mydata"
xdebug.trace_output_name="trace.%H.%t.%p"
xdebug.collect_params=3
```

##### PHP Tracer

XDebug tracer is a powerful tool that gives you the ability to analyze your PHP code, detect bottlenecks, and understand memory consumption at every step in a given flow.

<br/>

Reports are human-readable and are stored in the container's folder /tmp/mydata.  
Later I show you how to map that folder with a local folder in your host, to read those reports more easily.

<br/>

To enable the tracer, add the HTTP parameter **XDEBUG_TRACE** to any HTTP request. 
Again, you can use [Chrome's XDebug Helper](https://chrome.google.com/webstore/detail/xdebug-helper/eadndfjplgieldjbigjakmdgkmoaaaoc) to help you attach that param to any request.

</CodeWave>

<br/>

<br/>

#### The Dockerfile

Docker uses Dockerfiles as recipes to create images. Let's explore its syntax and a few useful instructions.

<CodeWave>

```docker
# My PHP Development environment
FROM php:7.4.2-apache
```

##### Use an official base image

**FROM** tells docker which base image has to use for subsequent instructions. 
Because of this, it's the first instruction on the Dockerfile.   
Every image is tagged with the following syntax:

<br/>

< **name** > **:** [ **version** ]

<br/>


Docker has a vibrant ecosystem of images you can use. One of the most popular repositories places to look for it's [DockerHub](https://hub.docker.com/), with thousands of publicly available repositories, built by DevOps practitioners around the world.  

<br/>

The image you choose must exist and you need to have access to it.  
Use the [official PHP image, bundled with Apache](https://hub.docker.com/_/php), whose name its "php", and its version "7.4.2-apache". 
If you want to check it's source code, [read its Dockerfile from Github](https://github.com/docker-library/php/blob/master/7.4/buster/apache/Dockerfile).  
To protect your image from upstream's breaking changes, always use explicit version tags. This principle applies to every external dependency you use in your projects, from Docker images to composer and npm packages.

<br/>

> For improved security and stability, your custom images should rely on [official images](https://docs.docker.com/docker-hub/official_images/); A curated list of images maintained by stricter quality standards

<br/>

```docker
# My PHP Development environment
FROM php:7.4.2-apache AS dev-image
```

##### Choose an alias for your image

An alias helps you reference one of your images in your build process. In this case, the alias is "**dev-image**".  

<br/>

Many image definitions can be written on the same Dockerfile.  
An alias helps you identify a specific image.

```docker
# My PHP Development environment
FROM php:7.4.2-apache AS dev-image
# Install XDebug
RUN pecl install xdebug-2.8.1
RUN docker-php-ext-enable xdebug
```

##### Run shell commands

First, install [XDebug](https://xdebug.org/); A development PHP extension that packs handy features to make your life easier as a developer.  
As [documented here](https://hub.docker.com/_/php), use _pecl_, and _docker-php-ext-enable_ instead of apt-get or other methods.  

<br/>

You can use RUN as many times as you want, but keep in mind it will generate a new layer, increasing the resulting image's size.

<br/>

```docker
# My PHP Development environment
FROM php:7.4.2-apache AS dev-image
# Install XDebug
RUN pecl install xdebug-2.9.2 \
    && docker-php-ext-enable xdebug
```

##### Optimize the size of your image

You can chain shell commands together to reduce the number of layers that compound an image.

> Unless you want to cache specific steps of your build process, it's a good practice to replace consecutive RUN lines, by a single line of chained sentences


```docker
# My PHP Development environment
FROM php:7.4.2-apache AS dev-image
# Install XDebug
RUN pecl install xdebug-2.9.2 \
    && docker-php-ext-enable xdebug \
# Create data folders for XDebug
# tracing and profiling tools
# and sets the ownership to www-data
    && mkdir -p /tmp/mydata \
    && chown -R www-data:www-data /tmp/mydata
# copy development settings for PHP
COPY ./config/development.ini /usr/local/etc/php/conf.d/
```

##### Configure PHP and XDebug

**COPY** allows you to copy files and folders from your host into your image.

1. Let's **RUN** a command to create a folder  /tmp/mydata inside your image; The place to store output files generated with XDebug tracer and profiler (see config/development.ini).
1. **COPY** the file config/development.ini into /usr/local/etc/php/conf.d/ inside your image, so PHP can load your settings automatically


```docker
# My PHP Development environment
FROM php:7.4.2-apache AS dev-image
# Install XDebug
RUN pecl install xdebug-2.9.2 \
    && docker-php-ext-enable xdebug \
# Create data folders for XDebug
# tracing and profiling tools
# and set ownership to www-data
    && mkdir -p /tmp/mydata \
    && chown -R www-data:www-data /tmp/mydata
# copy development settings for PHP
COPY ./config/development.ini /usr/local/etc/php/conf.d/
# copy the PHP source code inside your image
COPY --chown=www-data:www-data ./src /usr/local/project
# symling your project folder 
# with default's public apache folder
RUN ln -s /usr/local/project/public /var/www/html
```

##### Copy your project source code inside the image

1. **COPY** your local folder src/ into /usr/local/project inside your images, and assign the ownership of those files to user www-data
2. Then use **RUN** to symlink /var/www/html to /usr/local/project/public folder

**--chown=user:group** sets ownership of those files.

```docker
# My PHP Development environment
FROM php:7.4.2-apache AS dev-image
# Install XDebug
RUN pecl install xdebug-2.9.2 \
    && docker-php-ext-enable xdebug \
# Create data folders for XDebug
# tracing and profiling tools
# and set ownership to www-data
    && mkdir -p /tmp/mydata \
    && chown -R www-data:www-data /tmp/mydata
# copy development settings for PHP
COPY ./config/development.ini /usr/local/etc/php/conf.d/
# copy the PHP source code inside your image
COPY --chown=www-data:www-data ./src /usr/local/project
# symling your project folder 
# with default's public apache folder
RUN ln -s /usr/local/project/public /var/www/html
EXPOSE 80
```

##### Expose ports

**EXPOSE** open one or multiple ports in the container.

<br/>

This is just an example, cause there's no need to expose port 80 since it's been done already on the base image.  

<br/>

```docker
# My PHP Development environment
FROM php:7.4.2-apache AS dev-image
# Install XDebug
RUN pecl install xdebug-2.9.2 \
    && docker-php-ext-enable xdebug \
# Create data folders for XDebug
# tracing and profiling tools
# and set ownership to www-data
    && mkdir -p /tmp/mydata \
    && chown -R www-data:www-data /tmp/mydata
# copy development settings for PHP
COPY ./config/development.ini /usr/local/etc/php/conf.d/
# copy the PHP source code inside your image
COPY --chown=www-data:www-data ./src /usr/local/project
# symling your project folder 
# with default's public apache folder
RUN ln -s /usr/local/project/public /var/www/html
EXPOSE 80
```

##### And that's it!

You can now use this Dockerfile to build your custom image.

<br/>

Check [the Dockerfile reference](https://docs.docker.com/engine/reference/builder/) for a deep dive into every option available to write your own images, or customize this example.

</CodeWave>

<br/>

<br/>

### How to work with your image

#### Configure Docker

Before building the environment, allow Docker to read your project's folder.  
At least in Docker Desktop for MacOS, it goes like this:  

1. Go to Docker Desktop's preferences
2. Go to File Sharing, under Resources section
3. Add your folder and apply changes

Avoid symlinked folders cause Docker doesn't like them.

#### Commands

###### Build your image

<Code language="bash" snippet={`docker build -t my-project:1.0-development --target dev-image .`} />

Builds and tags your image as **my-project:1.0-development**.  
The last parameter ".", is the file system context at your docker host. Any file you want to **COPY** into the image must be inside the given context. 
You should allow docker to access your project's folder first. See the "File Sharing" settings section in Docker for Desktop.

<br/>

If everything went well, you should see the "**my-project**" custom image on that list.

<Code language="bash" snippet={`docker image ls`} />

<Code 
language="bash" 
snippet={`
REPOSITORY                  TAG                 IMAGE ID            CREATED             SIZE
dockerhub-user/my-project   1.0-development     14699ea162d0        2 minutes ago       885MB
`} />

###### Test it as a standalone container

Test your image before sharing it.  
Do not mount any volume, because you want to test the image itself as an immutable artifact.

<Code 
language="bash" 
snippet={`docker run --rm 
    -p 80:80/tcp 
    --name my-project-container 
    my-project:1.0-development`} 
/>

###### Run it as a development environment

How can you use this image as a development environment?  
Simply by mounting your source code inside the environment.

<br/>

Let's run a new container, with your source code mounted into it. 
And mount as well a local "data/" folder, as the folder where XDebug profiler and tracer dump their files inside the container. 
That way you can read them from your host.  
Use the **-v host-folder:container-folder** parameters for each volume.  
You should also use **--rm** to tell Docker to discard the container after using it.

<Code 
language="bash" 
snippet={`docker run --rm 
    -p 80:80/tcp
    -v "$PWD"/src:/usr/local/project 
    -v "$PWD"/data:/tmp/mydata 
    --name my-project-container 
    my-project:1.0-development`} 
/>

###### Share your image

To share it with other developers, push the image to your Dockerhub repo.

<Code 
language="bash" 
snippet={`docker login`}
/>

<Code 
language="bash" 
snippet={`docker push your-dockerhub-username/my-project`}
/>

<br/>

<br/>

#### Wrapping each workflow into a cohesive interface

Just like you would define an interface, or a group of public methods in a class, to present it as simple as possible to others. 
You should implement a simple and concise command-line interface, so devs and external tools can interact with the environment.  
Let's see now how to define a high-level command-line interface, by writing a Makefile; a pretty standard approach for IT teams and C projects.  
GNUMake it's a good fit for this task, because it allows you to write every high-level command in a single file, and it's a basic development tool, available on most operating systems.

<br/>

These are a few commands I like to define for projects in general:

- make build
- make clean
- make all
- make start
- make stop
- make test


<CodeWave>

```makefile
build:
	docker build \
    -t my-project:1.0-development \
    --target dev-image .
````

##### make build

Build the development environment.  
In the case of multiple environments, it should build every image required by any environment.  

<br/>

This command is used by the maintainers of the environment, and a CI/CD pipeline.


```makefile
start:
	docker run --rm \
    -p 80:80/tcp \
    -v ${PWD}/src:/var/www/html \
    -v ${PWD}/data:/tmp/mydata \
    --name my-project-container \
    acme/my-project:1.0-development
````

##### make start

Use this command to start a local development environment. It's usually used by developers involved in the project.  

- Docker starts my-project:1.0-development image from acme´s docker repository
- Map ports with the developer computer
- Assigns a name to the container (useful to write other commands like "make stop")
- Mount the source code inside the container so the environment can reflect changes made to the code.

```makefile
exec:
	@read -p "Command: " command; \
	docker exec \
    my-project-container \
    sh -c "$$command"
````

##### make exec

**make exec** it's a helper command that executes any command you pass to it inside the development environment, removing bugs caused by environments that differ from the production environment.

<br/>

###### Example commands you should run with **make exec**:

<Code language="bash" snippet={`composer init`} />

<Code language="bash" snippet={`composer install`} />

<Code language="bash" snippet={`composer update --save`} />

<Code language="bash" snippet={`composer require --save-dev phpunit`} />

<Code language="bash" snippet={`vendor/bin/phpunit your-tests/*.php`} />

<Code language="bash" snippet={`npm install`} />

<Code language="bash" snippet={`npm update`} />

<Code language="bash" snippet={`symfony cache:clear`} />

```makefile
stop: 
	-docker container stop my-project-container
````

##### make stop

This command stops the container previously started with **make start*

```makefile
clean: stop	
	-docker container rm my-project-container
	docker image rm my-project:1.0-development
````

##### make clean

This command removes any artifact created during the build by **make build**.  

<br/>

It's usually used by the maintainers of the environment and a CI/CD pipeline.

</CodeWave>

It's important to implement a common set of commands across projects to ease understanding and integration with automation tools. 
I like to use commands like build, clean, start, stop, deploy, test, all. 
Because they are concise and self-descriptive, besides being some of them pretty common across other projects I've seen in the wild.

<br/>

#### The README.md

Always remember to wrap your environment with a high-level documentation, so those who have to work with it can move faster without depending on you.  
Documentation is critical for communication, and reduce the dependency a team has on the maintainer of the environment.
It also helps to spread knowledge about the product, which is something very good if you plan to go on vacation someday.

<br/>

<hr/>

### Final thoughts

I hope you found this tutorial useful!  
Hopefully, you learned enough about Docker to build your own development environments.  
There is still more to learn though. This is a single container environment and it's not suitable for production. 
However, it's the cornerstone to modernize other processes and enable more enjoyable, collaborative ways of building software together.

<br/>

I did my best to guide you through this introductory exploration of Docker concepts, and a few use cases.
Above all, I tried to share a few technical tricks to improve collaboration and communication.

<br/>

Feel free to let me know any comments, critics, or suggestions you might have.  
You can write to me at <ContactLink/>

### What's next

In my next post, I'll show you how to build a production version of this environment, with **docker multi-stage builds**. 
How to create sandboxed **docker networks** to connect multiple containers together. 
And **docker-compose**, an interesting tool to declare your dev infrastructure in YAML format.

<br/>

**Stay tuned!**


