---
slug: "build-a-php-dev-environment-your-team-will-love/index.html"
title: "Build a PHP 7 development environment your team will love"
intro: "Learn to build a portable PHP development environment with Docker"
tools: "docker gnu-make php xdebug debian-linux"
date: "02-24-2020"
publish: true
blog: true
category: tutorial
---
import { CodeWave } from "gatsby-theme-waves"
import Code from "components/code"
import ContactLink from "components/contact-link"
import "prismjs/components/prism-docker"
import "prismjs/components/prism-ini"

> Welcome! This post it's a work in progress and will be changing during the next few days. 
> Don't hesitate to write me an email to <ContactLink/> with any comments, critics or advices you might have.

### Intro

I am convinced that human factors outweigh technical ones in the fate of most business ideas. 
Maybe it's because I studied psychology before getting back into software development. 
Or because I try to learn a little bit of the business and organizational side of the projects I get involved. 
After all, human time is more expensive than computing time.  
The same applies when we must design internal tools and processes; 
Empathy is key to increase the business outcomes produced with them.

<br />

In this post I use Docker to wrap a PHP project into a full fledged development environment. 
Built with features that hopefully, will help you and your team, become more effective on your day to day duties. 

### Requirements

You need **Docker engine** ( mine is 19.03 ), and **GNU Make**.

<br/>

The easiest way to setup Docker in Windows and MacOS is by getting [Docker Desktop](https://www.docker.com/products/docker-desktop).  
GNU Make might be already available in Windows through PowerShell, and its usually present on most popular Linux distros as well as MacOS.  
Linux users can get both via their default package manager. Two popular package managers for other environments are brew (MacOS), and chocolatey (Windows).

<br/>

Next, create a DockerHub account, and sign in from the command line.

<Code language="bash" snippet={`docker login`} />  

### Basic Docker concepts

With docker you can pack applications with their own runtime environment, provision it once, and deploy it into any machine, running a docker engine. 
Containers share the kernel of their host, and usually run a single process, bundled with the minimum operating system, files, and environment variables required. 
As a result, containers are lighter than virtual machines, and allow detailed resource administration.
Instead of long lasting dedicated servers, containerized infrastructure can be ephemeral and disposable.

##### Images

A Docker image it's the blueprint from where containers are created.  
For those comming from software development and object oriented programming, an image can be seen as a class and a container as an instance. 
An image it's just a stopped container.  
Custom images are extended from existing images, and can be shared with others by pushing them to docker repositories.

##### Windows Images vs Linux images

Docker can run two types of images: Linux or Windows images.  
The difference is the kernel they need to interact with in order to access hardware resources.  
It's possible to run Windows images on a computer running Linux, and visceversa, by running a docker engine on top of a virtual machine.
Both Windows and MacOS docker versions run Linux images by default, on top of a lightweight Linux VM. However Docker for Windows can spin up Windows images natively.  
In MacOS or Linux, you would need to setup a Windows VM as your docker host to do that.

##### Containerized file systems

You can copy files into an image from your host, add files from a url, create them by running shell commands, or mount a folder from your host as a volume. 
Each time one of those operations are performed, a new image layer wrap those changes, pretty much like source control commits.  
Every layer is identified with a unique hash ID. The layer at the top of the stack identifies the image like the last commit on a branch.  
You can create new containers from any layer on the stack. The resulting file system it's the sum of every stacked layer created before.  

##### Inmutable vs mutable images

As usual, maintaining state on your applications is harder than not having state at all. Because state introduces edge cases you must consider, and complicates testing.  
It's usually easier to cover every scenario when testing a codebase written with a functional approach than an object oriented alternative. 
And the same applies when we write code to automate infrastructure.

<br/>

Inmutable images are those that are built with every file needed by their main process, and you don't modify their state once deployed.  
Inmutable images allows you to implement simpler deployment processes, at the expense of longer build times.

##### Docker networking

Docker relies on the Container Network Model (CNM), a pluggable open-source architecture, to provide networking capabilities.  
CNM is extended to provide different network topologies. 
Docker supports the following implementations out of the box:

- Linux network drivers
    - bridge
    - overlay
    - macvlan
- Windows network drivers
    - nat
    - overlay
    - transparent
    - l2bridge

Many other implementations exist maintained by third parties.  

<br/>

Bridge are single host networks, and the default option when running Linux docker images. Their Windows counter part is NAT.

<br/>

#### Hello World

This website's is built inside a nodejs docker image.    
That means, you can run locally, the same version that's available at https://guille.cloud, without caring or knowing what's under the hoods. 
And do so any time you want, expecting the same results to happen each time.  
You could read it's [source code](https://github.com/guille-mas/blog/blob/master/Dockerfile) if you are curious about it.

<br/>

###### Go ahead and try it

<Code 
language="bash" 
snippet={`docker run --rm 
    -p 8080:8000 
    --name guillecloud 
    guillermomaschwitz/blog:1-production`} 
/>  

An exact version of this website should be available at http://0.0.0.0:8080 or http://localhost:8080. Your container has the same content you are reading in this tab.

<br/>

It should work out of the box, cause Docker did all the heavy lifting for you:

1. Attempts to find a local image tagged as **guillermomaschwitz/blog:1-production**, or pull it from its [Dockerhub repository](https://hub.docker.com/r/guillermomaschwitz/blog).
2. Starts a new container and name it **guillecloud**.
4. Bind port 8080 on your host with port 8000 on the container with the **-p** param. 
5. Stream logs to STDOUT and errors to STDERR

###### List every image pulled by docker

<Code language="bash" snippet={`docker image ls`} />  

<Code language="terminal" 
snippet={`
REPOSITORY                TAG                 IMAGE ID            CREATED             SIZE
guillermomaschwitz/blog   1                   14699ea162d0        2 hours ago         885MB
guillermomaschwitz/blog   1-production        14699ea162d0        2 hours ago         885MB
node                      13.1.0-alpine       f20a6d8b6721        3 months ago        105MB
`} 
/>

In this case, both TAGS for __guillermomaschwitz/blog__ belong to the same image, because both share the same IMAGE ID.

###### Check if your container is running

<Code language="bash" snippet={`docker container ls`} />  

<Code 
language="terminal"
snippet={`
CONTAINER ID        IMAGE                                  COMMAND                  CREATED             STATUS              PORTS                    NAMES
7ecd413bdf91        guillermomaschwitz/blog:1-production   "docker-entrypoint.sâ€¦"   23 minutes ago      Up 23 minutes       0.0.0.0:8000->8000/tcp   guillecloud
`}/>  

If everything went well, you should see a similar list in your terminal; A running container with a unique ID and NAME.

To list stopped containers as well, use the **-a** flag.  

###### Run a command inside the container

You can run bash and play inside your container

<Code language="bash" snippet={`docker exec -it guillecloud bash`} />

<Code language="terminal" 
snippet={`bash-5.0$ whoami
node
bash-5.0$ pwd
/home/node/blog
bash-5.0$ echo "I am inside a container!"
I am inside a container!
bash-5.0$ exit
exit
guille@localhost % `}/>

###### Stop the container

<Code language="bash" snippet={`docker stop guillecloud`} />

Because the container was started with the **--rm** flag, docker destroys the container once stopped.

###### Finally, remove the image

<Code language="bash" snippet={`docker image rm 14699ea162d0`} />

<br/>

Now, if you see the list of local images, you will see node's image.

<Code language="bash" snippet={`docker image ls`} />  

<Code language="terminal" 
snippet={`
REPOSITORY                TAG                 IMAGE ID            CREATED             SIZE
node                      13.1.0-alpine       f20a6d8b6721        3 months ago        105MB
`} 
/>

That's because node:13.1.0-alpine it's the base image on top of which, the image 14699ea162d0 (identified by tags "guillermomaschwitz/blog:1" and "guillermomaschwitz/blog:1-production") was built.

<hr/>

## The development environment

### The big picture

In this section, I show you the source code of a working docker development environment, with a very silly php codebase.  
Download [this sample PHP project](https://github.com/guille-mas/blog/tree/master/code-samples/php-docker-development-environment) from my Github account.  

##### Focus on the following files

###### The PHP configuration file

This file configures the behaviour of a decent PHP development environment. It's located in the config/ folder.

###### The Dockerfile

The rosetta stone of this tutorial; the file where we define the docker environment.

###### The Makefile

A high level cli interface other developers can use to interact with the development environment, while they get familiar with it.  
This is also the place, a CI/CD pipeline should rely on.

###### The README.md

Every project that you pass to other devs, should have a clear and concise README file in the root of the project. I won't cover this file's content, but you can read it's source code as an example on how it should look like.  
The information you put on this file should be the minimal amount of information, someone new to the project needs to adopt the tool without your guidance.  

###### Other files in the project

- **./src**
    - PHP code that shouldn't be exposed to the public
- **./src/public**
    - Files you want to expose to the public, like a front controller, static assets, etc
- **Makefile**
    - High level cli interface. Important to delay learning curve to others, and ease adoption of the environment.
- **./data**
    - Folder used by PHP's tracer and profiler to output reports.
- **.gitignore**
    - Flag files to exclude from GIT repo, like credentials, secrets, vendor files, build constructs, etc.
- **.dockerignore**
    - Flag files to exclude from Docker builds.

<br/>

<hr/>

#### The config/development.ini file

A development environment is different from a production environment, because it should help developers understand their codebase. 
To do so, I wrote the following configuration file. Let's see it.


<CodeWave>

```ini
###############################
# General
#############
error_reporting = E_ALL
display_startup_errors = On
display_errors = On
xdebug.var_display_max_depth=9
````
##### Display errors

Developers should have complete visibility over any error or exception that might rise at run time.

<br/>

They also need to see the data structures they work with ease. **xdebug.var_display_max_depth** affects how deep will go var_dump() function with complex arrays and objects.


```ini
###############################
# Debugger
# Disabled by default
# Triggered by an HTTP request
# containing the parameter 
# XDEBUG_SESSION_START
#############
xdebug.remote_enable=1
# Starting the remote debugger 
# makes the server reponses slower
# Instead, we will set an idekey 
# to trigger an attempt to connect
# to the dbgp client
xdebug.remote_autostart=0
xdebug.remote_host="host.docker.internal"
xdebug.remote_mode=req
# The port your IDE will use to wait 
# for a connection from xdebug
xdebug.remote_port=9001
````

##### PHP Remote Debugger

Using a debugger is way more effective than var_dump()'ing variables and refreshing the screen, but it slows down the execution of the program. 
These settings allow devs to enable a debugging session when they need so, by sending an  HTTP parameter to the server with name **XDEBUG_SESSION_START**, in their requests.  
When **XDEBUG_SESSION_START** is present on the request, in a GET, POST, PUT, DELETE, or UPDATE type of request, Xdebug will start the debugger.  
The debugger attempts to connect to the docker host ip, specified by the docker global variable **host.docker.internal**, and port 9001.

<br/>

Once you setup your IDE or editor to listen for connections into port 9001, you will be able to handle the debugger running from the containerized server, from your IDE.



```ini
###############################
# Profiler
# Disabled by default
# Triggered by an HTTP request
# containing the parameter 
# XDEBUG_PROFILE
#############
xdebug.cli_color=1
xdebug.profiler_enable=0
xdebug.profiler_enable_trigger=1
xdebug.profiler_output_dir="/tmp/mydata"
xdebug.profiler_output_name="cachegrind.out.%H.%t.%p"
````

##### PHP Profiler

Send an HTTP request with the parameter **XDEBUG_PROFILE**, a file is created at /tmp/mydata. 
A human readable list of every function call made, while your request was handled by the app.  
Total memory consumption will be reported at every step of the flow.


```ini
###############################
# Tracer
# Disabled by default
# Triggered by an HTTP request
# containing the parameter 
# XDEBUG_TRACE
#############
xdebug.trace_enable_trigger=1
xdebug.show_mem_delta=1
xdebug.trace_output_dir="/tmp/mydata"
xdebug.trace_output_name="trace.%H.%t.%p"
xdebug.collect_params=3
```

##### PHP Tracer

Send an HTTP request with the parameter **XDEBUG_TRACE**, to create a file at /tmp/mydata.
Then you can open the file in a tracer build program like https://github.com/kuun/xdebug-trace-viewer to get a complete tracer report.  
This is useful when you want to understand what happens on a new project, or how a framework works under the hoods.

</CodeWave>

<br/>

<hr/>

#### The Dockerfile

Docker uses Dockerfiles as recipes to create images. Let's explore it's syntax and a few useful instructions.

<CodeWave>

```docker
# My PHP Development environment
FROM php:7.4.2-apache
```

##### Use an official base image

**FROM** tells docker which base image has to use for subsequent instructions. 
Because of this, it's the first instruction on the Dockerfile.   
Every image is tagged with the following syntax:

<br/>

< **name** > **:** [ **version** ]

<br/>


Docker has a vibrant ecosystem of images you can use. One of the most popular repositories places to look for it's [DockerHub](https://hub.docker.com/), with thousands of publicly available repositories, built by devops practitioners around the world.  

<br/>

The image you choose must exist and you need to have access to it.  
Use the [official PHP image, bundled with Apache](https://hub.docker.com/_/php), whose name its "php", and its version "7.4.2-apache". 
If you want to check it's source code, [read its Dockerfile from Github](https://github.com/docker-library/php/blob/master/7.4/buster/apache/Dockerfile).  
To protect your image from upstream's breaking changes, always use explicit version tags. This principle applies to every external dependency you use in your projects, from Docker images to composer and npm packages.

<br/>

> For improved security and stability, your custom images should rely on [official images](https://docs.docker.com/docker-hub/official_images/); A curated list of images maintained by stricter quality standards

<br/>

```docker
# My PHP Development environment
FROM php:7.4.2-apache AS dev-image
```

##### Choose an alias for your image

An alias help you reference one of your images in your build process. In this case the alias is **dev-image**.  

<br/>

Many image definitions can be written on the same Dockerfile.  
An alias help you identify a specific image.

```docker
# My PHP Development environment
FROM php:7.4.2-apache AS dev-image
# Install XDebug
RUN pecl install xdebug-2.8.1
RUN docker-php-ext-enable xdebug
```

##### Run shell commands

First, install [XDebug](https://xdebug.org/); A development PHP extension that packs handy features to make your life easier as a developer.  
As [docummented here](https://hub.docker.com/_/php), use _pecl_, and _docker-php-ext-enable_ instead of apt-get or other methods.  

<br/>

You can use RUN as many times as you want, but every time you use it, a new layer gets added to the stack, increasing image size.

<br/>

```docker
# My PHP Development environment
FROM php:7.4.2-apache AS dev-image
# Install XDebug
RUN pecl install xdebug-2.9.2 \
    && docker-php-ext-enable xdebug
```

##### Optimize the size of your image

You can chain shell commands together in order to reduce the amount of layers that compound an image.

> Unless you want to cache specific steps of your build process, it's a good practice to replace consecutive RUN lines, by a single line of chained sentences


```docker
# My PHP Development environment
FROM php:7.4.2-apache AS dev-image
# Install XDebug
RUN pecl install xdebug-2.9.2 \
    && docker-php-ext-enable xdebug \
# Create data folders for XDebug
# tracing and profiling tools
# and set ownership to www-data
    && mkdir -p /tmp/mydata \
    && chown -R www-data:www-data /tmp/mydata
# copy development settings for PHP
COPY ./config/development.ini /usr/local/etc/php/conf.d/
```

##### Configure PHP and XDebug

**COPY** allows you to copy files and folders from your host into your image.

1. Let's **RUN** a command to create a folder  /tmp/mydata inside your image; The place to store output files generated with XDebug tracer and profiler (see config/development.ini).
1. **COPY** the file config/development.ini into /usr/local/etc/php/conf.d/ inside your image, so PHP can load your settings automatically


```docker
# My PHP Development environment
FROM php:7.4.2-apache AS dev-image
# Install XDebug
RUN pecl install xdebug-2.9.2 \
    && docker-php-ext-enable xdebug \
# Create data folders for XDebug
# tracing and profiling tools
# and set ownership to www-data
    && mkdir -p /tmp/mydata \
    && chown -R www-data:www-data /tmp/mydata
# copy development settings for PHP
COPY ./config/development.ini /usr/local/etc/php/conf.d/
# copy the PHP source code inside your image
COPY --chown=www-data:www-data ./src /usr/local/project
# symling your project folder 
# with default's public apache folder
RUN ln -s /usr/local/project/public /var/www/html
```

##### Copy your project source code inside the image

1. **COPY** your local folder src/ into /usr/local/project inside your images, and assign the ownership of those files to user www-data
2. Then use **RUN** to symlink /var/www/html to /usr/local/project/public folder

**--chown=user:group** sets ownership of those files.

```docker
# My PHP Development environment
FROM php:7.4.2-apache AS dev-image
# Install XDebug
RUN pecl install xdebug-2.9.2 \
    && docker-php-ext-enable xdebug \
# Create data folders for XDebug
# tracing and profiling tools
# and set ownership to www-data
    && mkdir -p /tmp/mydata \
    && chown -R www-data:www-data /tmp/mydata
# copy development settings for PHP
COPY ./config/development.ini /usr/local/etc/php/conf.d/
# copy the PHP source code inside your image
COPY --chown=www-data:www-data ./src /usr/local/project
# symling your project folder 
# with default's public apache folder
RUN ln -s /usr/local/project/public /var/www/html
EXPOSE 80
```

##### Expose ports

**EXPOSE** open one or multiple ports in the container.

<br/>

This is just an example, cause there's no need to expose port 80, since it's been done already on the base image.  

<br/>

```docker
# My PHP Development environment
FROM php:7.4.2-apache AS dev-image
# Install XDebug
RUN pecl install xdebug-2.9.2 \
    && docker-php-ext-enable xdebug \
# Create data folders for XDebug
# tracing and profiling tools
# and set ownership to www-data
    && mkdir -p /tmp/mydata \
    && chown -R www-data:www-data /tmp/mydata
# copy development settings for PHP
COPY ./config/development.ini /usr/local/etc/php/conf.d/
# copy the PHP source code inside your image
COPY --chown=www-data:www-data ./src /usr/local/project
# symling your project folder 
# with default's public apache folder
RUN ln -s /usr/local/project/public /var/www/html
EXPOSE 80
```

##### And that's it!

You can now use this Dockerfile to build your custom image.

<br/>

Check [the Dockerfile reference](https://docs.docker.com/engine/reference/builder/) for a deep dive into every option available to write your own images, or customize this example.

</CodeWave>

<br/>

<hr/>

### Basic docker workflows

### Previous Steps

Allow Docker to read your project's folder.  
At least in Docker Desktop for MacOS, it goes like this:  

1. Go to Docker Desktop's preferences
2. Go to File Sharing, under Resources section
3. Add your folder and apply changes

Avoid symlinked folders cause Docker doesnÂ´t like them.


#### Build your image

<Code language="bash" snippet={`docker build -t my-project:1.0-development --target dev-image .`} />

Builds and tags your image as **my-project:1.0-development**.  
The last parameter is the file system context at your docker host. Any file you want to **COPY** into the image, must be inside the given context. 
You should allow docker to access your project's folder first. See the "File Sharing" settings section in Docker for Desktop.

<br/>

If everything went well, you should see **my-project** custom image between your locally available images.

<Code language="bash" snippet={`docker image ls`} />

<Code language="bash" snippet={`docker image ls`} />

#### Test it as a standalone container

Test your image before sharing it.  
Do not mount any volume, to discard issues in the build process.

<Code 
language="bash" 
snippet={`docker run --rm 
    -p 80:80/tcp 
    --name my-project-container 
    my-project:1.0-development`} 
/>

#### Run it as a development environment

How can you use this image as a development environment?  
Simply by mounting your the folder containing your project code inside the environment.

<br/>

Let's run a new container, with your source code mounted into it. 
And mount as well a local "data/" folder, as the folder where XDebug profiler and tracer dump their files inside the container. 
That way you can read them from your host.  
Use the **-v host-folder:container-folder** parameters for each volume.  
You should also use **--rm** to tell Docker to discard the container after using it.

<Code 
language="bash" 
snippet={`docker run --rm 
    -p 80:80/tcp
    -v "$PWD"/src:/usr/local/project 
    -v "$PWD"/data:/tmp/mydata 
    --name my-project-container 
    my-project:1.0-development`} 
/>

#### Share your image

To share it with other developers, push the image to your Dockerhub repo.

<Code 
language="bash" 
snippet={`docker login`}
/>

<Code 
language="bash" 
snippet={`docker push your-dockerhub-username/my-project`}
/>

<br/>

<hr/>

#### The Makefile

Let's see now howto define a high level cli inteface to speed up on boarding, by hidding docker concepts behind a single file, with a friendly syntax, that's easy to read.


<CodeWave>

```makefile
# Bake an image of your development environment
build:
	docker build -t my-project:1.0-development --target dev-image .
````

##### make build


```makefile
# Bake an image of your development environment
build:
	docker build -t my-project:1.0-development --target dev-image .

start:
	docker run -p 80:80/tcp \
        -v ${PWD}/src:/var/www/html \
        -v ${PWD}/data:/tmp/mydata \
        --rm --name my-project-container \
        my-project:1.0-development

````

##### make start


```makefile
# Bake an image of your development environment
build:
	docker build -t my-project:1.0-development --target dev-image .

start:
	docker run -p 80:80/tcp \
        -v ${PWD}/src:/var/www/html \
        -v ${PWD}/data:/tmp/mydata \
        --rm --name my-project-container \
        my-project:1.0-development

exec:
	@read -p "Command to execute: " command; \
	docker exec my-project-container sh -c "$$command"

````

##### make exec


```makefile
# Bake an image of your development environment
build:
	docker build -t my-project:1.0-development --target dev-image .

start:
	docker run -p 80:80/tcp \
        -v ${PWD}/src:/var/www/html \
        -v ${PWD}/data:/tmp/mydata \
        --rm --name my-project-container \
        my-project:1.0-development

exec:
	@read -p "Command to execute: " command; \
	docker exec my-project-container sh -c "$$command"

stop: 
	-docker container stop my-project-container

````

##### make stop


```makefile
# Bake an image of your development environment
build:
	docker build -t my-project:1.0-development --target dev-image .

start:
	docker run -p 80:80/tcp \
        -v ${PWD}/src:/var/www/html \
        -v ${PWD}/data:/tmp/mydata \
        --rm --name my-project-container \
        my-project:1.0-development

exec:
	@read -p "Command to execute: " command; \
	docker exec my-project-container sh -c "$$command"

stop: 
	-docker container stop my-project-container

clean: stop	
	-docker container rm my-project-container
	docker image rm my-project:1.0-development

````

##### make clean

</CodeWave>

It's important to implement a common set of commands across projects to ease understanding and integration with automation tools. 
I like to use commands like: build, clean, start, stop, deploy, test, all. 
Because are concise and self descriptive, besides being some of them pretty common across other projects I've seen in the wild.

#### The README.md

Always remember to wrap your environment with a high level docummentation, so those who have to work with it, can move faster without depending on you.  
Docummentation is critical for communication, and reduce the dependency a team has on the maintainer of the environment.
It also helps to spread the knowledge about the product, which is something very good if you plan to go on vacations someday.

<br/>

I hope this first tutorial has been useful to you.  
Feel free to share your thoughts with me at <ContactLink/>

<hr/>

### Whats next

In the next post I show you how to build a production image as well with docker multi-stage builds. 
How to create sandboxed docker networks to connect multiple containers together. 
And **docker-compose**, an interesting tool to declare your dev infrastructure in yaml format.

<br/>

**Stay tuned!**


